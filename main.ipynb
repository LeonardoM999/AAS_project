{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670ed372",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/leonardo/Data/Projects/AAS/project/AAS_project/.venv2/lib/python3.10/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "from overcooked_ai_py.agents.agent import AgentPair\n",
    "from overcooked_ai_py.visualization.state_visualizer import StateVisualizer\n",
    "from overcooked_ai_py.agents.benchmarking import AgentEvaluator\n",
    "\n",
    "# from human_aware_rl.imitation.behavior_cloning_tf2 import (    _get_base_ae, BehaviorCloningPolicy)\n",
    "from overcooked_ai_py.mdp.overcooked_env import OvercookedEnv, Overcooked\n",
    "from overcooked_ai_py.mdp.overcooked_mdp import OvercookedGridworld\n",
    "from tqdm.auto import trange\n",
    "import warnings\n",
    "from gen_env import GeneralizedOvercooked\n",
    "\n",
    "from agent_policy import dumbAgent\n",
    "\n",
    "# warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"pygame.pkgdata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2db73a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_reward(reward):\n",
    "    warnings.warn(\"reward normalization not implemented\")\n",
    "    return reward\n",
    "\n",
    "\n",
    "def clip_reward(reward):\n",
    "    warnings.warni(\"reward clipping non implemented\")\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335454ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARGUMENTS:\n",
    "MAX_LEN_EPISODE = 400  # max number of frames per episode\n",
    "N_STEPS = 250  # ppo step = many rollouts + 1 backprop\n",
    "BUFFER_LEN = MAX_LEN_EPISODE * 5  # 7 10\n",
    "agent_name = \"ppo\"\n",
    "save_path = f\"weights\"\n",
    "lr = 1e-3  # 1e-4 2e-4 3e-4\n",
    "layout_name = \"cramped_room\"\n",
    "layout_name = \"asymmetric_advantages\"\n",
    "layout_name = \"coordination_ring\"\n",
    "discount_gamma = 0.99  # 0.995\n",
    "advantage_lambda = 0.95\n",
    "n_epochs = 7\n",
    "epsilon_greedy = 0.02\n",
    "val_epsilon_greedy = 1.0\n",
    "epsilon_clip = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc74fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train agent\n",
    "def train_agent():\n",
    "    \"\"\"\"\"\"\n",
    "    env = GeneralizedOvercooked()\n",
    "    my_agent = dumbAgent(buffer_len=BUFFER_LEN)\n",
    "\n",
    "    score_history = np.zeros((MAX_LEN_EPISODE,))  # total reward of each step\n",
    "    reward_history = np.zeros((MAX_LEN_EPISODE * N_STEPS,))  # single reward of each frame\n",
    "\n",
    "    # step = play 1 episode (forward pass), log episode and train (backward pass)\n",
    "    ## for each step\n",
    "    state, obs = env.reset()\n",
    "    # for step_n in trange(N_STEPS, colour=\"blue\", desc=\"Training steps\"):\n",
    "    step_n = 0  # TODO iterazione con for perchÃ¨ sappiamo quanti cicli dobbiamo fare\n",
    "    while step_n < N_STEPS:\n",
    "        print(f\"training ppo-step {step_n}\")\n",
    "        state, obs = env.reset()\n",
    "        print(f\"finished game {42}\")  # TODO\n",
    "        episode_over, total_reward = False, 0\n",
    "\n",
    "        # lenght of the episode is known/fixed\n",
    "        ## for each frame in the episode\n",
    "        for frame_n in trange(MAX_LEN_EPISODE):\n",
    "            ## act\n",
    "            obs1, obs2 = obs\n",
    "            action1, prob1, value1 = my_agent.act(obs1, state)\n",
    "            action2, prob2, value2 = my_agent.act(obs2, state)\n",
    "\n",
    "            ## step\n",
    "            next_state, next_obs, reward, episode_over, _info = env.step((action1, action2))\n",
    "\n",
    "            ## buffer\n",
    "            normalized_reward = normalize_reward(reward)\n",
    "            clipped_reward = clip_reward(reward)\n",
    "            # log reward for each action\n",
    "            reward_history[(step_n * MAX_LEN_EPISODE) + frame_n] = reward  # TODO which reward: clipped, normalized?\n",
    "            my_agent.store_step(\n",
    "                state,\n",
    "                obs1,\n",
    "                obs2,\n",
    "                action1,\n",
    "                action2,\n",
    "                prob1,\n",
    "                prob2,\n",
    "                value1,\n",
    "                value2,\n",
    "                normalized_reward,\n",
    "                episode_over,\n",
    "            )\n",
    "\n",
    "            total_reward += reward  # TODO which reward? clipped? normalized?\n",
    "\n",
    "            ## learn\n",
    "            if my_agent.buffer_full():\n",
    "                print(f\"cumulative reward (score): \")\n",
    "                my_agent.learn(n_epochs=7)\n",
    "                step_n += 1\n",
    "                if step_n % 3 == 0:  # TODO mettere a posto\n",
    "                    my_agent.save()\n",
    "\n",
    "            state, obs = next_state, next_obs\n",
    "\n",
    "        # TODO add statistics: rewards non shaped (metrica)\n",
    "        # log total scores for each episode\n",
    "        score_history[step_n] = total_reward\n",
    "\n",
    "    my_agent.save()\n",
    "    env.close()\n",
    "    # print/plot statistics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv2 (3.10.16)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
